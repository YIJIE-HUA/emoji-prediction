{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "絵文字をマージするかどうか"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "############################################################################################################\n",
    "# パラメータ設定\n",
    "# 絵文字をマージするかどうか\n",
    "emoji_merge = True\n",
    "# マージ元\n",
    "from_emoji = [\"😂\", \"💕\", \"☺️\", \"😃\", \"😆\", \"😁\", \"🥲\", \"👍\", \"✨\", \"☀️\", \"😅\", \"🥺\"]\n",
    "# マージ先\n",
    "to_emoji = [\"🤣\", \"🥰\", \"😊\", \"😊\", \"😊\", \"😊\", \"😭\", \"😊\", \"😊\", \"😊\", \"🤣\", \"😭\"]\n",
    "############################################################################################################"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "ファインチューニング・テスト用のデータセットの作成"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import json\n",
    "import random\n",
    "import pandas as pd\n",
    "\n",
    "\n",
    "# テストの時のテストデータの取得\n",
    "def get_test_data(dataset, num_per_label, completely_random, num_of_completely_random, create_json=False):\n",
    "\n",
    "    # completely random データの取り出し\n",
    "    if completely_random:\n",
    "        pass\n",
    "    # 各ラベルにつき、何個のデータを取り出す\n",
    "    else:\n",
    "        print(f\"データの抽出方法：各ラベルごとにランダムに {num_per_label} 件のデータを抽出する\")\n",
    "        # ラベルの取得\n",
    "        emojis = []\n",
    "        for d in dataset:\n",
    "            if d[\"label\"] not in emojis:\n",
    "                emojis.append(d[\"label\"])\n",
    "        #print(len(emojis))\n",
    "        #print(emojis)\n",
    "\n",
    "        # テストデータセットの作成\n",
    "        test_dataset = []\n",
    "        for i in range(0, len(emojis), 1):\n",
    "            test_dataset_temp = [d for d in dataset if d[\"label\"] == emojis[i]]\n",
    "            test_dataset_temp = random.sample(test_dataset_temp, num_per_label)\n",
    "            for d in test_dataset_temp:\n",
    "                test_dataset.append(d)\n",
    "        #print(len(test_dataset))\n",
    "        #print(test_dataset)\n",
    "        print(f\"データは全部で {num_per_label}（各ラベルごとのデータ数） * {len(emojis)}（ラベル数） = {len(test_dataset)} 件\")\n",
    "\n",
    "        # json ファイルの作成\n",
    "        if create_json:\n",
    "            json_path = f\"./dataset/test/test_{len(test_dataset)}_dataset.json\"\n",
    "            with open(json_path, 'w', encoding='utf-8') as f:\n",
    "                json.dump(test_dataset, f, indent=4, ensure_ascii=False)\n",
    "\n",
    "        return test_dataset\n",
    "\n",
    "\n",
    "def get_ft_dataset(num_per_label, ft_random=True):\n",
    "    ############################################################################################################\n",
    "    # パラメータ設定\n",
    "    # json ファイルパス\n",
    "    json_path = \"./dataset/top20_one_emoji_dataset.json\"\n",
    "    # 既存の訓練データセットのパス\n",
    "    training_path = \"./dataset/train_gpt/R8.json\"\n",
    "    ############################################################################################################\n",
    "    \n",
    "    # json ファイルの読み込み\n",
    "    with open(json_path, 'r') as f:\n",
    "        dataset = json.load(f)\n",
    "    #print(len(dataset))\n",
    "\n",
    "    # データをランダムに取り出す、テストデータの作成と一緒\n",
    "    if ft_random:\n",
    "        ft_dataset = get_test_data(dataset=dataset,\n",
    "                                   num_per_label=num_per_label,\n",
    "                                   completely_random=False,\n",
    "                                   num_of_completely_random=False\n",
    "                                   )\n",
    "        #print(len(ft_dataset))\n",
    "        #print(ft_dataset[0])\n",
    "\n",
    "        ft_dataset = [\n",
    "            {\"messages\": [{\"role\": \"user\", \"content\": f\"{d['text']}というツイートに最も相応しい絵文字はどれ？\\n選択肢：😅、☀️、☺️、😆、😂、😭、✨、🤣、🥺、🎉、🥰、🥲、😃、💕、💦、😇、😊、👍、😁、🤔\"},\n",
    "                          {\"role\": \"assistant\", \"content\": d[\"label\"]}]}\n",
    "            for d in ft_dataset\n",
    "        ]\n",
    "        #print(ft_dataset)\n",
    "\n",
    "        ft_dataset = pd.DataFrame(ft_dataset)\n",
    "        ft_dataset.to_json(\"./dataset/train_gpt/dataset_temp.jsonl\", force_ascii=False, lines=True, orient=\"records\")\n",
    "    # 既存のデータセットを取得する\n",
    "    else:\n",
    "        # 既存のデータセットを読み込む\n",
    "        with open(training_path, 'r') as f:\n",
    "            ft_dataset = [json.loads(d) for d in f.readlines()]\n",
    "        #print(len(ft_dataset))\n",
    "        #print(ft_dataset[0])\n",
    "\n",
    "        ft_dataset = [\n",
    "            {\"messages\": [\n",
    "                {\"role\": \"user\", \"content\": d['messages'][0]['content']},\n",
    "                {\"role\": \"assistant\", \"content\": d['messages'][1]['content']}\n",
    "            ]}\n",
    "            for d in ft_dataset\n",
    "        ]\n",
    "        #print(len(ft_dataset))\n",
    "        #print(ft_dataset[0])\n",
    "\n",
    "        ft_dataset = pd.DataFrame(ft_dataset)\n",
    "        ft_dataset.to_json(\"./dataset/train_gpt/dataset_temp.jsonl\", force_ascii=False, lines=True, orient=\"records\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "推論"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import json\n",
    "import time\n",
    "import emoji\n",
    "import openai\n",
    "from openai import OpenAI\n",
    "\n",
    "\n",
    "def main():\n",
    "\n",
    "    ############################################################################################################\n",
    "    # パラメータ設定\n",
    "    # id\n",
    "    result_id = \"GPT35_1\"\n",
    "    # json ファイルのパス\n",
    "    json_path = \"./dataset/top20_one_emoji_dataset.json\"\n",
    "    # テストデータセットを作成するかどうか\n",
    "    create_test_dataset = False\n",
    "    # 既存のテストデータを読み込む用\n",
    "    test_path = \"./dataset/test/T8h.json\"\n",
    "    # 使うモデル\n",
    "    model = \"gpt-3.5-turbo-1106\"\n",
    "    # temperature（出力のランダム性）\n",
    "    temperature = 0\n",
    "    # テストだけの時のテストは completely random かどうか、False 各ラベルにつき、何個のデータを取り出すか\n",
    "    completely_random = False\n",
    "    # completely random の時の取り出すデータの数\n",
    "    num_of_completely_random = 200\n",
    "    # ファインチューニング・テストだけの時の各ラベルにつき、何個のデータを取り出すか\n",
    "    num_per_label = 20\n",
    "    # json ファイルに出力かどうか\n",
    "    create_json = True\n",
    "    ############################################################################################################\n",
    "\n",
    "    # api key をロードする\n",
    "    client = OpenAI()\n",
    "\n",
    "    # json ファイルの読み込み\n",
    "    with open(json_path, 'r') as f:\n",
    "        topn_one_emoji_dataset = json.load(f)\n",
    "    #print(len(topn_one_emoji_dataset))\n",
    "    #print(topn_one_emoji_dataset[2])\n",
    "\n",
    "    # テスト\n",
    "    if create_test_dataset:\n",
    "        test_dataset = get_test_data(\n",
    "            dataset=topn_one_emoji_dataset,\n",
    "            num_per_label=num_per_label,\n",
    "            completely_random=completely_random,\n",
    "            num_of_completely_random=num_of_completely_random,\n",
    "            create_json=create_json\n",
    "            )\n",
    "    else:\n",
    "        with open(test_path, 'r') as f:\n",
    "            test_dataset = json.load(f)\n",
    "\n",
    "    # 絵文字をマージする\n",
    "    if emoji_merge:\n",
    "        test_dataset_temp = []\n",
    "        for d in test_dataset:\n",
    "            if d[\"label\"] in from_emoji:\n",
    "                d[\"label\"] = to_emoji[from_emoji.index(d[\"label\"])]\n",
    "                test_dataset_temp.append(d)\n",
    "            else:\n",
    "                test_dataset_temp.append(d)\n",
    "        test_dataset = test_dataset_temp\n",
    "\n",
    "    output = []\n",
    "    correct_output = []\n",
    "    wrong_output = []\n",
    "    for d in test_dataset:\n",
    "\n",
    "        # GPT の入力形式に変換する\n",
    "        messages = [\n",
    "            {\"role\": \"user\", \"content\": f\"{d['text']}というツイートに最も相応しい絵文字を選択肢の中から一つ選んでください。\\\n",
    "なお、選んだ一つの絵文字だけ回答してください。\\\n",
    "\\nただし、🎉は「おめでとう」のようなお祝いの言葉の後にしか付けない、\\\n",
    "🥰は「好き」、「幸せ」、「素敵」を表現する、\\\n",
    "😇は「終わった」、「もうダメ」、「天使」に関連して使う、\\\n",
    "💦は「ストレス」、「緊張」、「汗」、「暑さ」に関連して使う\\\n",
    "という条件がある。\\\n",
    "\\n選択肢：😊、🤣、😭、🎉、🥰、😇、💦、🤔\"}\n",
    "        ]\n",
    "\n",
    "        # レスポンスを生成する\n",
    "        try:\n",
    "            time.sleep(5)\n",
    "            response = client.chat.completions.create(\n",
    "                model=model,\n",
    "                messages=messages,\n",
    "                temperature=temperature\n",
    "                )\n",
    "        except openai.APITimeoutError:\n",
    "            time.sleep(120)\n",
    "            response = client.chat.completions.create(\n",
    "                model=model,\n",
    "                messages=messages,\n",
    "                temperature=temperature\n",
    "                )\n",
    "\n",
    "        # モデルが生成した絵文字は一つだけかどうかをチェック\n",
    "        # wrong\n",
    "        if emoji.emoji_count(response.choices[0].message.content, unique=True) != 1:\n",
    "            output_temp = {\n",
    "                \"モデル\": response.model,\n",
    "                \"temperature\": temperature,\n",
    "                \"入力\": {\"role\": messages[0]['role'], \"content\": messages[0]['content']},\n",
    "                \"出力\": {\"role\": response.choices[0].message.role, \"content\": response.choices[0].message.content},\n",
    "                \"プロンプトトークン数\": response.usage.prompt_tokens,\n",
    "                \"出力トークン数\": response.usage.completion_tokens,\n",
    "                \"総トークン数\": response.usage.total_tokens,\n",
    "                \"予測\": emoji.distinct_emoji_list(response.choices[0].message.content),\n",
    "                \"正解\": d[\"label\"],\n",
    "                \"正誤\": \"false\"\n",
    "                }\n",
    "            output.append(output_temp)\n",
    "            wrong_output.append(output_temp)\n",
    "        # correct\n",
    "        else:\n",
    "            # 正解\n",
    "            if emoji.distinct_emoji_list(response.choices[0].message.content)[0] == d[\"label\"]:\n",
    "                output_temp = {\n",
    "                    \"モデル\": response.model,\n",
    "                    \"temperature\": temperature,\n",
    "                    \"入力\": {\"role\": messages[0]['role'], \"content\": messages[0]['content']},\n",
    "                    \"出力\": {\"role\": response.choices[0].message.role, \"content\": response.choices[0].message.content},\n",
    "                    \"プロンプトトークン数\": response.usage.prompt_tokens,\n",
    "                    \"出力トークン数\": response.usage.completion_tokens,\n",
    "                    \"総トークン数\": response.usage.total_tokens,\n",
    "                    \"予測\": emoji.distinct_emoji_list(response.choices[0].message.content)[0],\n",
    "                    \"正解\": d[\"label\"],\n",
    "                    \"正誤\": \"true\"\n",
    "                    }\n",
    "                output.append(output_temp)\n",
    "                correct_output.append(output_temp)\n",
    "            # 不正解\n",
    "            else:\n",
    "                output_temp = {\n",
    "                    \"モデル\": response.model,\n",
    "                    \"temperature\": temperature,\n",
    "                    \"入力\": {\"role\": messages[0]['role'], \"content\": messages[0]['content']},\n",
    "                    \"出力\": {\"role\": response.choices[0].message.role, \"content\": response.choices[0].message.content},\n",
    "                    \"プロンプトトークン数\": response.usage.prompt_tokens,\n",
    "                    \"出力トークン数\": response.usage.completion_tokens,\n",
    "                    \"総トークン数\": response.usage.total_tokens,\n",
    "                    \"予測\": emoji.distinct_emoji_list(response.choices[0].message.content)[0],\n",
    "                    \"正解\": d[\"label\"],\n",
    "                    \"正誤\": \"false\"\n",
    "                    }\n",
    "                output.append(output_temp)\n",
    "                correct_output.append(output_temp)\n",
    "    print(f\"絵文字が一つだけの出力の数： {len(correct_output)}\")\n",
    "    print(f\"絵文字が一つじゃないの出力の数： {len(wrong_output)}\")\n",
    "\n",
    "    # json ファイルの出力\n",
    "    # 全部\n",
    "    json_path = f\"./results/{result_id}/{model.replace('personal::', '').replace('-', '_')}_output.json\"\n",
    "    with open(json_path, 'w', encoding='utf-8') as f:\n",
    "        json.dump(output, f, indent=4, ensure_ascii=False)\n",
    "\n",
    "    # 絵文字が一つだけの出力\n",
    "    json_path = f\"./results/{result_id}/{model.replace('personal::', '').replace('-', '_')}_correct_output.json\"\n",
    "    with open(json_path, 'w', encoding='utf-8') as f:\n",
    "        json.dump(correct_output, f, indent=4, ensure_ascii=False)\n",
    "\n",
    "    # 絵文字が一つじゃない出力\n",
    "    json_path = f\"./results/{result_id}/{model.replace('personal::', '').replace('-', '_')}_wrong_output.json\"\n",
    "    with open(json_path, 'w', encoding='utf-8') as f:\n",
    "        json.dump(wrong_output, f, indent=4, ensure_ascii=False)\n",
    "    \n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "    main()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "ラベルの取得・マッピング"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "import json\n",
    "\n",
    "\n",
    "# ラベルの取得\n",
    "def get_label(json_path):\n",
    "    with open(json_path, 'r') as f:\n",
    "        dataset = json.load(f)\n",
    "\n",
    "    # ラベルの取得（出現回数に関係ない）\n",
    "    label = []\n",
    "    for d in dataset:\n",
    "        if d[\"正解\"] not in label:\n",
    "            label.append(d[\"正解\"])\n",
    "   \n",
    "    return label"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "推論、精度計算"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import json\n",
    "import numpy as np\n",
    "from sklearn.metrics import classification_report, ConfusionMatrixDisplay\n",
    "\n",
    "\n",
    "def main():\n",
    "\n",
    "    ############################################################################################################\n",
    "    # パラメータ設定\n",
    "    # id\n",
    "    result_id = \"GPT35_1\"\n",
    "    # モデル\n",
    "    model = \"gpt-3.5-turbo-1106\"\n",
    "    # json ファイルパス\n",
    "    json_path = \"./results/GPT35_1/gpt_3.5_turbo_1106_output.json\"\n",
    "    ############################################################################################################\n",
    "\n",
    "    # ラベルの取得\n",
    "    label = get_label(json_path=json_path)\n",
    "    #print(len(label))\n",
    "    print('、'.join(label))\n",
    "    \n",
    "    # json ファイルの読み込み\n",
    "    json_path = f\"./results/{result_id}/{model.replace('personal::', '').replace('-', '_')}_output.json\"\n",
    "    with open(json_path, 'r') as f:\n",
    "        output = json.load(f)\n",
    "    #print(len(output))\n",
    "    json_path = f\"/results/{result_id}/{model.replace('personal::', '').replace('-', '_')}_correct_output.json\"\n",
    "    with open(json_path, 'r') as f:\n",
    "        correct_output = json.load(f)\n",
    "    #print(len(correct_output))\n",
    "\n",
    "    # 用意したラベル以外の絵文字が予測された数\n",
    "    num_of_not_in_label = 0\n",
    "    for d in correct_output:\n",
    "        if d[\"予測\"] not in label:\n",
    "            num_of_not_in_label = num_of_not_in_label + 1\n",
    "    print(f\"用意したラベル以外の絵文字が予測された数: {num_of_not_in_label}\")\n",
    "\n",
    "    # Acc 計算\n",
    "    num_of_true = len([d[\"正誤\"] for d in output if d[\"正誤\"] == \"true\"])\n",
    "    print(f\"正解数： {num_of_true}\")\n",
    "    print(f\"Acc： {(num_of_true / len(output)) * 100}\")\n",
    "\n",
    "    # P R F1 計算\n",
    "    label_gold = np.array([d[\"正解\"] for d in correct_output])\n",
    "    label_pred = np.array([d[\"予測\"] for d in correct_output])\n",
    "    print(classification_report(y_true=label_gold, y_pred=label_pred, labels=label, zero_division=0.0))\n",
    "\n",
    "    ConfusionMatrixDisplay.from_predictions(y_true=label_gold, y_pred=label_pred, labels=label)\n",
    "\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "    main()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "emoji_prediction",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.18"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
